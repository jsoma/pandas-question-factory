{"datasets": [[{"country": "Kyrgyzstan", "continent": "Asia", "life_expectancy": 66.2, "population": 4955000, "gdp": 7566000000}, {"country": "Brazil", "continent": "S. America", "life_expectancy": 70.3, "population": 174425000, "gdp": 1405171000000}, {"country": "Belarus", "continent": "Europe", "life_expectancy": 69.0, "population": 10058000, "gdp": 59703000000}, {"country": "Hungary", "continent": "Europe", "life_expectancy": 71.9, "population": 10211000, "gdp": 138782000000}, {"country": "United States", "continent": "N. America", "life_expectancy": 76.8, "population": 282496000, "gdp": 11231488000000}], [{"status": "Implementation", "year": 2017, "country": "Kenya", "region": "EA", "borrowerCode": null, "borrowerType": null, "borrowerNotGouv": "Government", "financier": "Eximbank", "financeType": "Loan", "group": 1.0, "reportedValue": 201, "reportedUnit": "CNY", "cleanUSD": 31, "interestRate": "2", "liborRate": null, "repayment": 10.0, "grace": null, "term": null, "purpose": "Karimenu Dam Water Supply Project"}, {"status": "Implementation", "year": 2006, "country": "Kenya", "region": "EA", "borrowerCode": null, "borrowerType": null, "borrowerNotGouv": "Government", "financier": "Eximbank", "financeType": "CL", "group": 1.0, "reportedValue": 196, "reportedUnit": "CNY", "cleanUSD": 25, "interestRate": "2", "liborRate": null, "repayment": null, "grace": 6.0, "term": "19", "purpose": "Rural Telecommunications Development Project"}, {"status": "Implementation", "year": 2017, "country": "Angola", "region": "CA", "borrowerCode": null, "borrowerType": null, "borrowerNotGouv": "Government", "financier": "Eximbank", "financeType": "Loan", "group": 1.0, "reportedValue": 65, "reportedUnit": "USD", "cleanUSD": 65, "interestRate": null, "liborRate": null, "repayment": null, "grace": null, "term": null, "purpose": "National Geology Plan Project"}, {"status": "Signed", "year": 2011, "country": "Tanzania", "region": "EA", "borrowerCode": null, "borrowerType": null, "borrowerNotGouv": "Government", "financier": "CIDCA", "financeType": "ZIL", "group": 1.0, "reportedValue": 15, "reportedUnit": "USD", "cleanUSD": 15, "interestRate": "0", "liborRate": null, "repayment": null, "grace": null, "term": null, "purpose": "Unknown"}, {"status": "Implementation", "year": 2019, "country": "South Africa", "region": "SA", "borrowerCode": 2.0, "borrowerType": "AfrStateCom", "borrowerNotGouv": "Electricity Supply Commission (ESKOM) (SOE)", "financier": "CDB", "financeType": "MFA-sub", "group": 1.0, "reportedValue": 600, "reportedUnit": "USD", "cleanUSD": 600, "interestRate": null, "liborRate": null, "repayment": null, "grace": null, "term": null, "purpose": "Medupi Coal Power Plant expansion (6X794=4800MW) Tranche B"}], [{"Case Number": "ME2016-05779", "Date of Incident": "12/02/2016 11:30:00 AM", "Date of Death": "12/02/2016 02:20:00 PM", "Age": 47.0, "Gender": "Male", "Race": "Black", "Latino": false, "Manner of Death": "ACCIDENT", "Primary Cause": "FENTANYL AND PROBABLE HEROIN TOXICITY", "Primary Cause Line A": null, "Primary Cause Line B": null, "Primary Cause Line C": null, "Secondary Cause": "CHRONIC OBSTRUCTIVE PULMONARY DISEASE", "Gun Related": false, "Opioid Related": true, "Cold Related": false, "Heat Related": false, "Commissioner District": 2.0, "Incident Address": "3527 W. Flournoy St. Apt 1", "Incident City": "CHICAGO", "Incident Zip Code": "60624", "longitude": -87.714, "latitude": 41.872, "location": "(41.87246045964478, -87.71427253232721)", "Residence City": "Chicago", "Residence Zip": 60624.0, "OBJECTID": 18793, "Chicago Ward": 24.0, "Chicago Community Area": "EAST GARFIELD PARK"}, {"Case Number": "ME2015-01232", "Date of Incident": "03/25/2015 01:00:00 PM", "Date of Death": "03/25/2015 01:30:00 PM", "Age": 92.0, "Gender": "Male", "Race": "White", "Latino": false, "Manner of Death": "NATURAL", "Primary Cause": "HYPERTENSIVE AND ARTERIOSCLEROTIC CARDIOVASCULAR DISEASE", "Primary Cause Line A": null, "Primary Cause Line B": null, "Primary Cause Line C": null, "Secondary Cause": null, "Gun Related": false, "Opioid Related": false, "Cold Related": false, "Heat Related": false, "Commissioner District": 10.0, "Incident Address": "712 W. Diversey #509", "Incident City": "CHICAGO", "Incident Zip Code": "60614", "longitude": -87.647, "latitude": 41.933, "location": "(41.93291999289584, -87.647258194165)", "Residence City": "Chicago", "Residence Zip": 60614.0, "OBJECTID": 14787, "Chicago Ward": 44.0, "Chicago Community Area": "LAKE VIEW"}, {"Case Number": "ME2017-02383", "Date of Incident": "05/14/2017 08:00:00 PM", "Date of Death": "05/25/2017 04:14:00 AM", "Age": 32.0, "Gender": "Male", "Race": "White", "Latino": false, "Manner of Death": "ACCIDENT", "Primary Cause": "BLUNT FORCE TRAUMA OF HEAD", "Primary Cause Line A": "FALL", "Primary Cause Line B": null, "Primary Cause Line C": null, "Secondary Cause": null, "Gun Related": false, "Opioid Related": false, "Cold Related": false, "Heat Related": false, "Commissioner District": null, "Incident Address": "131 FIRST STR.", "Incident City": "NEW LENOX", "Incident Zip Code": "60451", "longitude": null, "latitude": null, "location": null, "Residence City": "New Lenox", "Residence Zip": 60451.0, "OBJECTID": 3838, "Chicago Ward": null, "Chicago Community Area": null}, {"Case Number": "ME2015-03338", "Date of Incident": "08/05/2015 11:30:00 AM", "Date of Death": "08/05/2015 12:25:00 PM", "Age": 80.0, "Gender": "Female", "Race": "White", "Latino": false, "Manner of Death": "NATURAL", "Primary Cause": "HYPERTENSIVE CARDIOVASCULAR DISEASE", "Primary Cause Line A": null, "Primary Cause Line B": null, "Primary Cause Line C": null, "Secondary Cause": null, "Gun Related": false, "Opioid Related": false, "Cold Related": false, "Heat Related": false, "Commissioner District": 10.0, "Incident Address": "4300 N. MARINE DR #1005", "Incident City": "CHICAGO", "Incident Zip Code": "60613", "longitude": -87.647, "latitude": 41.961, "location": "(41.96126004223558, -87.64738594848397)", "Residence City": "Chicago", "Residence Zip": 60613.0, "OBJECTID": 14548, "Chicago Ward": 46.0, "Chicago Community Area": "UPTOWN"}, {"Case Number": "ME2014-00664", "Date of Incident": "09/20/2014 02:18:00 PM", "Date of Death": "09/20/2014 02:41:00 PM", "Age": 50.0, "Gender": "Male", "Race": "Black", "Latino": false, "Manner of Death": "NATURAL", "Primary Cause": "HYPERTENSIVE ARTERIOSCLEROTIC CARDIOVASCULAR DISEASE", "Primary Cause Line A": null, "Primary Cause Line B": null, "Primary Cause Line C": null, "Secondary Cause": null, "Gun Related": false, "Opioid Related": false, "Cold Related": false, "Heat Related": false, "Commissioner District": null, "Incident Address": "817 MEADOW LANE", "Incident City": "STREAMWOOD", "Incident Zip Code": "60107", "longitude": null, "latitude": null, "location": null, "Residence City": "Streamwood", "Residence Zip": 60107.0, "OBJECTID": 7546, "Chicago Ward": null, "Chicago Community Area": null}]], "questions": [{"desc": "where population is greater than or equal to 2411000 and gdp is less than or equal to 21687000000, count the frequency of each value of continent", "code": "df[(df.population >= 2411000) & (df.gdp <= 21687000000)].continent.value_counts()", "difficulty": 3, "dataset_id": 0}, {"desc": "display all rows  where population is equal to 4107000,", "code": "df[df.population == 4107000]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows  where gdp is less than or equal to 203310000000 and population is equal to 3694000,", "code": "df[(df.gdp <= 203310000000) & (df.population == 3694000)]", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows for a dataframe named df2,  where population is greater than 2003000.0,", "code": "df2[df2.population > 2003000.0]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows", "code": "df", "difficulty": 0, "dataset_id": 0}, {"desc": "where population is less than or equal to 146758000, calculate the mean of life_expectancy", "code": "df[df.population <= 146758000].life_expectancy.mean()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where life_expectancy is equal to 58.5,", "code": "df[df.life_expectancy == 58.5]", "difficulty": 1, "dataset_id": 0}, {"desc": "where population is greater than or equal to 6015000 and gdp is greater than or equal to 20450000000, calculate the median of life_expectancy", "code": "df[(df.population >= 6015000) & (df.gdp >= 20450000000)].life_expectancy.median()", "difficulty": 3, "dataset_id": 0}, {"desc": "where life_expectancy is less than or equal to 74.4 and population is equal to 11237000, count the frequency of each value of continent", "code": "df[(df.life_expectancy <= 74.4) & (df.population == 11237000)].continent.value_counts()", "difficulty": 3, "dataset_id": 0}, {"desc": "display all rows  where population is greater than or equal to 1297000,", "code": "df[df.population >= 1297000]", "difficulty": 1, "dataset_id": 0}, {"desc": "where gdp is greater than or equal to 37375000000, calculate the median of life_expectancy", "code": "df[df.gdp >= 37375000000].life_expectancy.median()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where population is equal to 1196000,", "code": "df[df.population == 1196000]", "difficulty": 1, "dataset_id": 0}, {"desc": "where life_expectancy is greater than or equal to 52.2, calculate the median of population", "code": "df[df.life_expectancy >= 52.2].population.median()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows", "code": "df", "difficulty": 0, "dataset_id": 0}, {"desc": "display all rows for a dataframe named df2,  where life_expectancy is less than 74.12 and gdp is greater than or equal to 50960000000,", "code": "df2[(df2.life_expectancy < 74.12) & (df2.gdp >= 50960000000)]", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where population is greater than 8338450.0,", "code": "df[df.population > 8338450.0]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows for a dataframe named merged,  where gdp is less than 12453600000.0 and life_expectancy is less than 71.51,", "code": "merged[(merged.gdp < 12453600000.0) & (merged.life_expectancy < 71.51)]", "difficulty": 2, "dataset_id": 0}, {"desc": "where life_expectancy is less than or equal to 62.8 and population is equal to 435000 and gdp is greater than 138077870000.0, count the frequency of each value of continent (as a percent)", "code": "df[(df.life_expectancy <= 62.8) & (df.population == 435000) & (df.gdp > 138077870000.0)].continent.value_counts(normalize=True)", "difficulty": 4, "dataset_id": 0}, {"desc": "display all rows for a dataframe named merged,", "code": "merged", "difficulty": 0, "dataset_id": 0}, {"desc": "display all rows  where life_expectancy is equal to 70.5,", "code": "df[df.life_expectancy == 70.5]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows  where gdp is equal to 14013000000,", "code": "df[df.gdp == 14013000000]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows  where population is greater than 6006750.0,", "code": "df[df.population > 6006750.0]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows  where population is greater than or equal to 1235000,", "code": "df[df.population >= 1235000]", "difficulty": 1, "dataset_id": 0}, {"desc": "for a dataframe named merged,  where population is greater than or equal to 78758000, calculate the sum of gdp", "code": "merged[merged.population >= 78758000].gdp.sum()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where population is less than 5019260.0,", "code": "df[df.population < 5019260.0]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows  where population is greater than 2494790.0,", "code": "df[df.population > 2494790.0]", "difficulty": 1, "dataset_id": 0}, {"desc": "calculate the median of population", "code": "df.population.median()", "difficulty": 1, "dataset_id": 0}, {"desc": "for a dataframe named merged,  where gdp is less than or equal to 155661000000, calculate the mean of life_expectancy", "code": "merged[merged.gdp <= 155661000000].life_expectancy.mean()", "difficulty": 2, "dataset_id": 0}, {"desc": "where life_expectancy is greater than or equal to 54.9, calculate the mean of population", "code": "df[df.life_expectancy >= 54.9].population.mean()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows for a dataframe named merged,  where population is greater than or equal to 6015000,", "code": "merged[merged.population >= 6015000]", "difficulty": 1, "dataset_id": 0}, {"desc": "where life_expectancy is less than 70.32, count the frequency of each value of continent", "code": "df[df.life_expectancy < 70.32].continent.value_counts()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where gdp is less than 36684150000.0,", "code": "df[df.gdp < 36684150000.0]", "difficulty": 1, "dataset_id": 0}, {"desc": "where gdp is less than or equal to 20450000000, calculate the sum of population", "code": "df[df.gdp <= 20450000000].population.sum()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where life_expectancy is greater than or equal to 67.8,", "code": "df[df.life_expectancy >= 67.8]", "difficulty": 1, "dataset_id": 0}, {"desc": "where life_expectancy is greater than or equal to 74.4, calculate the median of gdp", "code": "df[df.life_expectancy >= 74.4].gdp.median()", "difficulty": 2, "dataset_id": 0}, {"desc": "for a dataframe named df2,  where life_expectancy is greater than 73.2, count the frequency of each value of continent", "code": "df2[df2.life_expectancy > 73.2].continent.value_counts()", "difficulty": 2, "dataset_id": 0}, {"desc": "where life_expectancy is less than 67.71, calculate the median of population", "code": "df[df.life_expectancy < 67.71].population.median()", "difficulty": 2, "dataset_id": 0}, {"desc": "where gdp is greater than 18273960000.0, calculate the median of life_expectancy", "code": "df[df.gdp > 18273960000.0].life_expectancy.median()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where gdp is less than or equal to 400926000000 and life_expectancy is greater than 73.19 and population is less than 2494790.0,", "code": "df[(df.gdp <= 400926000000) & (df.life_expectancy > 73.19) & (df.population < 2494790.0)]", "difficulty": 3, "dataset_id": 0}, {"desc": "display all rows  where gdp is equal to 1386000000,", "code": "df[df.gdp == 1386000000]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows  where gdp is less than 10455960000.0,", "code": "df[df.gdp < 10455960000.0]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows  where population is less than or equal to 3319000,", "code": "df[df.population <= 3319000]", "difficulty": 1, "dataset_id": 0}, {"desc": "where gdp is equal to 35690000000, count the frequency of each value of continent", "code": "df[df.gdp == 35690000000].continent.value_counts()", "difficulty": 2, "dataset_id": 0}, {"desc": "for a dataframe named df2,  where gdp is greater than 24991000000.0, calculate the median of population", "code": "df2[df2.gdp > 24991000000.0].population.median()", "difficulty": 2, "dataset_id": 0}, {"desc": "where life_expectancy is less than 67.24, count the frequency of each value of continent (as a percent)", "code": "df[df.life_expectancy < 67.24].continent.value_counts(normalize=True)", "difficulty": 2, "dataset_id": 0}, {"desc": "where gdp is less than or equal to 891000000, calculate the median of population", "code": "df[df.gdp <= 891000000].population.median()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where life_expectancy is equal to 79.3,", "code": "df[df.life_expectancy == 79.3]", "difficulty": 1, "dataset_id": 0}, {"desc": "for a dataframe named merged,  where life_expectancy is equal to 64.6 and gdp is less than or equal to 94261000000 and population is greater than 2339020.0, count the frequency of each value of continent (as a percent, including missing values)", "code": "merged[(merged.life_expectancy == 64.6) & (merged.gdp <= 94261000000) & (merged.population > 2339020.0)].continent.value_counts(normalize=True, dropna=False)", "difficulty": 4, "dataset_id": 0}, {"desc": "display all rows  where gdp is greater than 139788520000.0,", "code": "df[df.gdp > 139788520000.0]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows for a dataframe named df2,  where life_expectancy is less than 72.1,", "code": "df2[df2.life_expectancy < 72.1]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows  where population is equal to 3919000,", "code": "df[df.population == 3919000]", "difficulty": 1, "dataset_id": 0}, {"desc": "where life_expectancy is greater than 68.66 and gdp is equal to 2447907000000, calculate the mean of population", "code": "df[(df.life_expectancy > 68.66) & (df.gdp == 2447907000000)].population.mean()", "difficulty": 3, "dataset_id": 0}, {"desc": "where gdp is greater than or equal to 14013000000, count the frequency of each value of continent", "code": "df[df.gdp >= 14013000000].continent.value_counts()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where gdp is equal to 613000000 and population is equal to 7399000 and life_expectancy is greater than 60.07,", "code": "df[(df.gdp == 613000000) & (df.population == 7399000) & (df.life_expectancy > 60.07)]", "difficulty": 3, "dataset_id": 0}, {"desc": "where life_expectancy is less than or equal to 78.1 and population is greater than 15844500.0, calculate the median of gdp", "code": "df[(df.life_expectancy <= 78.1) & (df.population > 15844500.0)].gdp.median()", "difficulty": 3, "dataset_id": 0}, {"desc": "display all rows for a dataframe named merged,  where population is greater than 11844450.0 and gdp is greater than 21814890000.0,", "code": "merged[(merged.population > 11844450.0) & (merged.gdp > 21814890000.0)]", "difficulty": 2, "dataset_id": 0}, {"desc": "for a dataframe named df2,  where gdp is greater than 39693280000.0 and population is equal to 5405000, calculate the sum of life_expectancy", "code": "df2[(df2.gdp > 39693280000.0) & (df2.population == 5405000)].life_expectancy.sum()", "difficulty": 3, "dataset_id": 0}, {"desc": "where population is less than 8338450.0, calculate the mean of life_expectancy", "code": "df[df.population < 8338450.0].life_expectancy.mean()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows", "code": "df", "difficulty": 0, "dataset_id": 0}, {"desc": "calculate the mean of gdp", "code": "df.gdp.mean()", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows for a dataframe named df2,  where gdp is equal to 6765000000,", "code": "df2[df2.gdp == 6765000000]", "difficulty": 1, "dataset_id": 0}, {"desc": "where population is less than or equal to 5940000, calculate the mean of life_expectancy", "code": "df[df.population <= 5940000].life_expectancy.mean()", "difficulty": 2, "dataset_id": 0}, {"desc": "where population is greater than or equal to 1941000, count the frequency of each value of continent (as a percent)", "code": "df[df.population >= 1941000].continent.value_counts(normalize=True)", "difficulty": 2, "dataset_id": 0}, {"desc": "for a dataframe named merged,  where gdp is equal to 9320000000 and population is equal to 144522000, calculate the sum of life_expectancy", "code": "merged[(merged.gdp == 9320000000) & (merged.population == 144522000)].life_expectancy.sum()", "difficulty": 3, "dataset_id": 0}, {"desc": "for a dataframe named df2,  count the frequency of each value of continent (as a percent)", "code": "df2.continent.value_counts(normalize=True)", "difficulty": 1, "dataset_id": 0}, {"desc": "where life_expectancy is greater than 74.12, calculate the sum of population", "code": "df[df.life_expectancy > 74.12].population.sum()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where life_expectancy is greater than 74.12 and population is greater than or equal to 5173000,", "code": "df[(df.life_expectancy > 74.12) & (df.population >= 5173000)]", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows for a dataframe named df2,  where life_expectancy is greater than or equal to 76.7,", "code": "df2[df2.life_expectancy >= 76.7]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows  where population is greater than 3619280.0 and life_expectancy is greater than 69.76 and gdp is less than or equal to 13171000000,", "code": "df[(df.population > 3619280.0) & (df.life_expectancy > 69.76) & (df.gdp <= 13171000000)]", "difficulty": 3, "dataset_id": 0}, {"desc": "display all rows  where life_expectancy is equal to 72.1,", "code": "df[df.life_expectancy == 72.1]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows  where life_expectancy is less than 63.9,", "code": "df[df.life_expectancy < 63.9]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows", "code": "df", "difficulty": 0, "dataset_id": 0}, {"desc": "where gdp is greater than or equal to 4008000000, count the frequency of each value of continent", "code": "df[df.gdp >= 4008000000].continent.value_counts()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where gdp is less than 33964600000.0 and population is less than 4163880.0,", "code": "df[(df.gdp < 33964600000.0) & (df.population < 4163880.0)]", "difficulty": 2, "dataset_id": 0}, {"desc": "where population is less than or equal to 8111000 and gdp is greater than or equal to 28268000000, calculate the sum of life_expectancy", "code": "df[(df.population <= 8111000) & (df.gdp >= 28268000000)].life_expectancy.sum()", "difficulty": 3, "dataset_id": 0}, {"desc": "where life_expectancy is less than or equal to 50.9, count the frequency of each value of continent (as a percent)", "code": "df[df.life_expectancy <= 50.9].continent.value_counts(normalize=True)", "difficulty": 2, "dataset_id": 0}, {"desc": "for a dataframe named merged,  where gdp is greater than 47800200000.0, calculate the median of population", "code": "merged[merged.gdp > 47800200000.0].population.median()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where population is greater than 15844500.0,", "code": "df[df.population > 15844500.0]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows", "code": "df", "difficulty": 0, "dataset_id": 0}, {"desc": "display all rows  where gdp is greater than or equal to 33576000000,", "code": "df[df.gdp >= 33576000000]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows  where gdp is greater than 8599640000.0,", "code": "df[df.gdp > 8599640000.0]", "difficulty": 1, "dataset_id": 0}, {"desc": "where life_expectancy is less than or equal to 62.0 and gdp is less than 17719210000.0, calculate the median of population", "code": "df[(df.life_expectancy <= 62.0) & (df.gdp < 17719210000.0)].population.median()", "difficulty": 3, "dataset_id": 0}, {"desc": "where population is greater than or equal to 24401000 and gdp is greater than 145713750000.0, calculate the median of life_expectancy", "code": "df[(df.population >= 24401000) & (df.gdp > 145713750000.0)].life_expectancy.median()", "difficulty": 3, "dataset_id": 0}, {"desc": "display all rows  where life_expectancy is greater than 66.91,", "code": "df[df.life_expectancy > 66.91]", "difficulty": 1, "dataset_id": 0}, {"desc": "where gdp is less than 9394980000.0, calculate the median of life_expectancy", "code": "df[df.gdp < 9394980000.0].life_expectancy.median()", "difficulty": 2, "dataset_id": 0}, {"desc": "where gdp is greater than or equal to 1478000000, count the frequency of each value of continent", "code": "df[df.gdp >= 1478000000].continent.value_counts()", "difficulty": 2, "dataset_id": 0}, {"desc": "where population is greater than or equal to 28793000, calculate the sum of gdp", "code": "df[df.population >= 28793000].gdp.sum()", "difficulty": 2, "dataset_id": 0}, {"desc": "where life_expectancy is greater than 73.65, calculate the mean of gdp", "code": "df[df.life_expectancy > 73.65].gdp.mean()", "difficulty": 2, "dataset_id": 0}, {"desc": "where gdp is greater than or equal to 37375000000, calculate the sum of life_expectancy", "code": "df[df.gdp >= 37375000000].life_expectancy.sum()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows for a dataframe named merged,  where gdp is equal to 13561000000,", "code": "merged[merged.gdp == 13561000000]", "difficulty": 1, "dataset_id": 0}, {"desc": "for a dataframe named df2,  where gdp is greater than 33298650000.0, calculate the mean of population", "code": "df2[df2.gdp > 33298650000.0].population.mean()", "difficulty": 2, "dataset_id": 0}, {"desc": "display all rows  where life_expectancy is less than or equal to 75.1,", "code": "df[df.life_expectancy <= 75.1]", "difficulty": 1, "dataset_id": 0}, {"desc": "where gdp is equal to 1088960000000 and population is equal to 1371000, calculate the median of life_expectancy", "code": "df[(df.gdp == 1088960000000) & (df.population == 1371000)].life_expectancy.median()", "difficulty": 3, "dataset_id": 0}, {"desc": "display all rows for a dataframe named df2,  where population is equal to 1292000,", "code": "df2[df2.population == 1292000]", "difficulty": 1, "dataset_id": 0}, {"desc": "for a dataframe named df2,  count the frequency of each value of continent (as a percent)", "code": "df2.continent.value_counts(normalize=True)", "difficulty": 1, "dataset_id": 0}, {"desc": "where life_expectancy is greater than 73.2 and population is greater than or equal to 48892000 and gdp is greater than 21480200000.0, count the frequency of each value of continent", "code": "df[(df.life_expectancy > 73.2) & (df.population >= 48892000) & (df.gdp > 21480200000.0)].continent.value_counts()", "difficulty": 4, "dataset_id": 0}, {"desc": "display all rows  where gdp is greater than 11969320000.0,", "code": "df[df.gdp > 11969320000.0]", "difficulty": 1, "dataset_id": 0}, {"desc": "display all rows for a dataframe named df2,  where population is greater than or equal to 11229000,", "code": "df2[df2.population >= 11229000]", "difficulty": 1, "dataset_id": 0}, {"desc": "where population is less than or equal to 27193000, calculate the mean of gdp", "code": "df[df.population <= 27193000].gdp.mean()", "difficulty": 2, "dataset_id": 0}, {"desc": "where population is equal to 733000, calculate the mean of life_expectancy", "code": "df[df.population == 733000].life_expectancy.mean()", "difficulty": 2, "dataset_id": 0}, {"desc": "where borrowerCode is less than or equal to 7.0, display the top 10 most common values in liborRate", "code": "df[df.borrowerCode <= 7.0].liborRate.value_counts().head(10)", "difficulty": 2, "dataset_id": 1}, {"desc": "where group is less than or equal to 2.0 and year is greater than or equal to 2019, count the frequency of each value of country (as a percent, including missing values)", "code": "df[(df.group <= 2.0) & (df.year >= 2019)].country.value_counts(normalize=True, dropna=False)", "difficulty": 3, "dataset_id": 1}, {"desc": "for a dataframe named merged,  where grace is greater than 5.0 and interestRate is not missing, calculate the median of cleanUSD", "code": "merged[(merged.grace > 5.0) & merged.interestRate.notna()].cleanUSD.median()", "difficulty": 3, "dataset_id": 1}, {"desc": "display all rows for a dataframe named df2,  where liborRate is missing,", "code": "df2[df2.liborRate.isna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "where reportedValue is less than or equal to 2, count the frequency of each value of borrowerNotGouv (as a percent)  for each value of liborRate,", "code": "df[df.reportedValue <= 2].groupby('liborRate').borrowerNotGouv.value_counts(normalize=True)", "difficulty": 3, "dataset_id": 1}, {"desc": "for a dataframe named df2,  where reportedValue is equal to 72, display the top 5 most common values in liborRate", "code": "df2[df2.reportedValue == 72].liborRate.value_counts().head(5)", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows  where grace is missing and reportedValue is greater than 28.0,", "code": "df[df.grace.isna() & (df.reportedValue > 28.0)]", "difficulty": 2, "dataset_id": 1}, {"desc": "for a dataframe named df2,  calculate the mean of cleanUSD", "code": "df2.cleanUSD.mean()", "difficulty": 1, "dataset_id": 1}, {"desc": "display all rows for a dataframe named merged,  where borrowerCode is not missing,", "code": "merged[merged.borrowerCode.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "where liborRate is not missing, calculate the mean of cleanUSD", "code": "df[df.liborRate.notna()].cleanUSD.mean()", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows  where repayment is not missing,", "code": "df[df.repayment.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "for a dataframe named merged,  calculate the sum of reportedValue for each value of liborRate,", "code": "merged.groupby('liborRate').reportedValue.sum()", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows  where borrowerType is not missing and repayment is missing,", "code": "df[df.borrowerType.notna() & df.repayment.isna()]", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows for a dataframe named df2,  where borrowerCode is not missing,", "code": "df2[df2.borrowerCode.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "display all rows  where borrowerCode is greater than or equal to 3.0 and repayment is not missing,", "code": "df[(df.borrowerCode >= 3.0) & df.repayment.notna()]", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows for a dataframe named merged,  where repayment is less than or equal to 10.0,", "code": "merged[merged.repayment <= 10.0]", "difficulty": 1, "dataset_id": 1}, {"desc": "display all rows  where reportedValue is equal to 2110,", "code": "df[df.reportedValue == 2110]", "difficulty": 1, "dataset_id": 1}, {"desc": "where year is greater than 2015.0 and borrowerCode is not missing and term is missing, display the top 8 most common values in liborRate", "code": "df[(df.year > 2015.0) & df.borrowerCode.notna() & df.term.isna()].liborRate.value_counts().head(8)", "difficulty": 4, "dataset_id": 1}, {"desc": "display all rows  where grace is not missing,", "code": "df[df.grace.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "where group is equal to 2.0, display the top 7 most common values in liborRate, including missing values", "code": "df[df.group == 2.0].liborRate.value_counts(dropna=False).head(7)", "difficulty": 2, "dataset_id": 1}, {"desc": "for a dataframe named df2,  where group is equal to 2.0, display the top 6 most common values in liborRate", "code": "df2[df2.group == 2.0].liborRate.value_counts().head(6)", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows for a dataframe named merged,", "code": "merged", "difficulty": 0, "dataset_id": 1}, {"desc": "display all rows  where interestRate is not missing,", "code": "df[df.interestRate.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "display all rows  where borrowerCode is not missing,", "code": "df[df.borrowerCode.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "where year is less than or equal to 2005, calculate the sum of reportedValue for each value of liborRate,", "code": "df[df.year <= 2005].groupby('liborRate').reportedValue.sum()", "difficulty": 3, "dataset_id": 1}, {"desc": "where interestRate is not missing, count the frequency of each value of borrowerType", "code": "df[df.interestRate.notna()].borrowerType.value_counts()", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows  where repayment is not missing,", "code": "df[df.repayment.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "count the frequency of each value of borrowerType for each value of liborRate,", "code": "df.groupby('liborRate').borrowerType.value_counts()", "difficulty": 2, "dataset_id": 1}, {"desc": "calculate the mean of cleanUSD", "code": "df.cleanUSD.mean()", "difficulty": 1, "dataset_id": 1}, {"desc": "where grace is greater than 5.0, calculate the sum of cleanUSD", "code": "df[df.grace > 5.0].cleanUSD.sum()", "difficulty": 2, "dataset_id": 1}, {"desc": "for a dataframe named merged,  where borrowerCode is greater than 2.0, calculate the sum of cleanUSD for each value of liborRate,", "code": "merged[merged.borrowerCode > 2.0].groupby('liborRate').cleanUSD.sum()", "difficulty": 3, "dataset_id": 1}, {"desc": "where grace is greater than or equal to 11.0 and repayment is not missing, calculate the mean of reportedValue for each value of liborRate,", "code": "df[(df.grace >= 11.0) & df.repayment.notna()].groupby('liborRate').reportedValue.mean()", "difficulty": 4, "dataset_id": 1}, {"desc": "display all rows for a dataframe named merged,  where reportedValue is greater than 30.0,", "code": "merged[merged.reportedValue > 30.0]", "difficulty": 1, "dataset_id": 1}, {"desc": "where group is greater than 1.0, display the top 7 most common values in liborRate", "code": "df[df.group > 1.0].liborRate.value_counts().head(7)", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows  where borrowerType is missing,", "code": "df[df.borrowerType.isna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "for a dataframe named df2,  where borrowerCode is greater than 3.0, count the frequency of each value of country (as a percent)", "code": "df2[df2.borrowerCode > 3.0].country.value_counts(normalize=True)", "difficulty": 2, "dataset_id": 1}, {"desc": "where year is greater than or equal to 2007 and borrowerCode is less than 3.0, calculate the mean of cleanUSD for each value of liborRate,", "code": "df[(df.year >= 2007) & (df.borrowerCode < 3.0)].groupby('liborRate').cleanUSD.mean()", "difficulty": 4, "dataset_id": 1}, {"desc": "display all rows for a dataframe named df2,  where borrowerCode is not missing and liborRate is not missing,", "code": "df2[df2.borrowerCode.notna() & df2.liborRate.notna()]", "difficulty": 2, "dataset_id": 1}, {"desc": "for a dataframe named merged,  where reportedValue is greater than or equal to 513, count the frequency of each value of term for each value of liborRate,", "code": "merged[merged.reportedValue >= 513].groupby('liborRate').term.value_counts()", "difficulty": 3, "dataset_id": 1}, {"desc": "where repayment is not missing, calculate the mean of cleanUSD", "code": "df[df.repayment.notna()].cleanUSD.mean()", "difficulty": 2, "dataset_id": 1}, {"desc": "where liborRate is not missing and interestRate is not missing and repayment is not missing, calculate the mean of cleanUSD", "code": "df[df.liborRate.notna() & df.interestRate.notna() & df.repayment.notna()].cleanUSD.mean()", "difficulty": 4, "dataset_id": 1}, {"desc": "where reportedValue is greater than 28.0 and interestRate is not missing, calculate the mean of cleanUSD for each value of liborRate,", "code": "df[(df.reportedValue > 28.0) & df.interestRate.notna()].groupby('liborRate').cleanUSD.mean()", "difficulty": 4, "dataset_id": 1}, {"desc": "display all rows  where grace is not missing,", "code": "df[df.grace.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "for a dataframe named merged,  where term is not missing, calculate the sum of cleanUSD for each value of liborRate,", "code": "merged[merged.term.notna()].groupby('liborRate').cleanUSD.sum()", "difficulty": 3, "dataset_id": 1}, {"desc": "display all rows for a dataframe named merged,  where reportedValue is greater than or equal to 322 and grace is less than 5.0,", "code": "merged[(merged.reportedValue >= 322) & (merged.grace < 5.0)]", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows  where term is not missing,", "code": "df[df.term.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "for a dataframe named df2,  where repayment is not missing, count the frequency of each value of borrowerNotGouv (as a percent, including missing values)", "code": "df2[df2.repayment.notna()].borrowerNotGouv.value_counts(normalize=True, dropna=False)", "difficulty": 2, "dataset_id": 1}, {"desc": "calculate the mean of cleanUSD", "code": "df.cleanUSD.mean()", "difficulty": 1, "dataset_id": 1}, {"desc": "display all rows for a dataframe named df2,  where cleanUSD is less than 33.0,", "code": "df2[df2.cleanUSD < 33.0]", "difficulty": 1, "dataset_id": 1}, {"desc": "where liborRate is not missing, calculate the median of reportedValue", "code": "df[df.liborRate.notna()].reportedValue.median()", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows  where borrowerType is not missing and repayment is greater than 15.0,", "code": "df[df.borrowerType.notna() & (df.repayment > 15.0)]", "difficulty": 2, "dataset_id": 1}, {"desc": "where borrowerCode is not missing and grace is greater than or equal to 5.5, display the top 4 most common values in liborRate, including missing values", "code": "df[df.borrowerCode.notna() & (df.grace >= 5.5)].liborRate.value_counts(dropna=False).head(4)", "difficulty": 3, "dataset_id": 1}, {"desc": "where borrowerCode is less than or equal to 3.0 and repayment is greater than or equal to 16.5, count the frequency of each value of reportedUnit", "code": "df[(df.borrowerCode <= 3.0) & (df.repayment >= 16.5)].reportedUnit.value_counts()", "difficulty": 3, "dataset_id": 1}, {"desc": "where borrowerCode is not missing, calculate the mean of reportedValue", "code": "df[df.borrowerCode.notna()].reportedValue.mean()", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows", "code": "df", "difficulty": 0, "dataset_id": 1}, {"desc": "where term is missing and borrowerType is not missing, count the frequency of each value of financeType", "code": "df[df.term.isna() & df.borrowerType.notna()].financeType.value_counts()", "difficulty": 3, "dataset_id": 1}, {"desc": "where borrowerType is not missing, count the frequency of each value of financeType (as a percent)", "code": "df[df.borrowerType.notna()].financeType.value_counts(normalize=True)", "difficulty": 2, "dataset_id": 1}, {"desc": "where borrowerType is not missing, display the top 8 most common values in liborRate for each value of liborRate,", "code": "df[df.borrowerType.notna()].groupby('liborRate').liborRate.value_counts().head(8)", "difficulty": 3, "dataset_id": 1}, {"desc": "display all rows  where liborRate is not missing,", "code": "df[df.liborRate.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "display all rows for a dataframe named merged,  where borrowerCode is less than 3.0,", "code": "merged[merged.borrowerCode < 3.0]", "difficulty": 1, "dataset_id": 1}, {"desc": "display all rows  where grace is greater than 5.0,", "code": "df[df.grace > 5.0]", "difficulty": 1, "dataset_id": 1}, {"desc": "display all rows  where borrowerCode is equal to 7.0,", "code": "df[df.borrowerCode == 7.0]", "difficulty": 1, "dataset_id": 1}, {"desc": "for a dataframe named df2,  where year is greater than 2014.0 and cleanUSD is less than or equal to 330, calculate the mean of reportedValue for each value of liborRate,", "code": "df2[(df2.year > 2014.0) & (df2.cleanUSD <= 330)].groupby('liborRate').reportedValue.mean()", "difficulty": 4, "dataset_id": 1}, {"desc": "where repayment is missing, calculate the mean of cleanUSD", "code": "df[df.repayment.isna()].cleanUSD.mean()", "difficulty": 2, "dataset_id": 1}, {"desc": "where repayment is not missing, display the top 6 most common values in liborRate, including missing values for each value of liborRate,", "code": "df[df.repayment.notna()].groupby('liborRate').liborRate.value_counts(dropna=False).head(6)", "difficulty": 3, "dataset_id": 1}, {"desc": "where liborRate is not missing, calculate the sum of cleanUSD", "code": "df[df.liborRate.notna()].cleanUSD.sum()", "difficulty": 2, "dataset_id": 1}, {"desc": "where interestRate is not missing and borrowerCode is not missing, calculate the median of cleanUSD", "code": "df[df.interestRate.notna() & df.borrowerCode.notna()].cleanUSD.median()", "difficulty": 3, "dataset_id": 1}, {"desc": "where grace is not missing and liborRate is not missing, count the frequency of each value of status", "code": "df[df.grace.notna() & df.liborRate.notna()].status.value_counts()", "difficulty": 3, "dataset_id": 1}, {"desc": "where term is not missing, calculate the median of reportedValue for each value of liborRate,", "code": "df[df.term.notna()].groupby('liborRate').reportedValue.median()", "difficulty": 3, "dataset_id": 1}, {"desc": "display all rows for a dataframe named merged,  where cleanUSD is greater than 13.0 and repayment is less than or equal to 7.0,", "code": "merged[(merged.cleanUSD > 13.0) & (merged.repayment <= 7.0)]", "difficulty": 2, "dataset_id": 1}, {"desc": "where repayment is not missing, calculate the median of cleanUSD for each value of liborRate,", "code": "df[df.repayment.notna()].groupby('liborRate').cleanUSD.median()", "difficulty": 3, "dataset_id": 1}, {"desc": "where reportedValue is less than or equal to 205 and repayment is less than 13.0, calculate the median of cleanUSD", "code": "df[(df.reportedValue <= 205) & (df.repayment < 13.0)].cleanUSD.median()", "difficulty": 3, "dataset_id": 1}, {"desc": "display all rows for a dataframe named df2,  where borrowerCode is not missing,", "code": "df2[df2.borrowerCode.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "where grace is not missing, calculate the median of cleanUSD", "code": "df[df.grace.notna()].cleanUSD.median()", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows for a dataframe named df2,  where borrowerCode is not missing,", "code": "df2[df2.borrowerCode.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "for a dataframe named merged,  where group is equal to 2.0 and repayment is less than 13.0, calculate the median of cleanUSD", "code": "merged[(merged.group == 2.0) & (merged.repayment < 13.0)].cleanUSD.median()", "difficulty": 3, "dataset_id": 1}, {"desc": "count the frequency of each value of country (as a percent)", "code": "df.country.value_counts(normalize=True)", "difficulty": 1, "dataset_id": 1}, {"desc": "display all rows  where group is equal to 2.0 and cleanUSD is greater than 29.0,", "code": "df[(df.group == 2.0) & (df.cleanUSD > 29.0)]", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows  where liborRate is not missing,", "code": "df[df.liborRate.notna()]", "difficulty": 1, "dataset_id": 1}, {"desc": "where grace is not missing, calculate the median of cleanUSD for each value of liborRate,", "code": "df[df.grace.notna()].groupby('liborRate').cleanUSD.median()", "difficulty": 3, "dataset_id": 1}, {"desc": "display all rows  where grace is missing and borrowerType is not missing and repayment is greater than 10.0,", "code": "df[df.grace.isna() & df.borrowerType.notna() & (df.repayment > 10.0)]", "difficulty": 3, "dataset_id": 1}, {"desc": "where repayment is less than 13.0 and borrowerCode is equal to 6.0, count the frequency of each value of borrowerNotGouv (as a percent)", "code": "df[(df.repayment < 13.0) & (df.borrowerCode == 6.0)].borrowerNotGouv.value_counts(normalize=True)", "difficulty": 3, "dataset_id": 1}, {"desc": "where grace is less than or equal to 5.0, count the frequency of each value of financeType", "code": "df[df.grace <= 5.0].financeType.value_counts()", "difficulty": 2, "dataset_id": 1}, {"desc": "where liborRate is not missing and term is missing, calculate the sum of cleanUSD", "code": "df[df.liborRate.notna() & df.term.isna()].cleanUSD.sum()", "difficulty": 3, "dataset_id": 1}, {"desc": "where group is greater than 1.0 and year is less than 2016.0, count the frequency of each value of term (as a percent)  for each value of liborRate,", "code": "df[(df.group > 1.0) & (df.year < 2016.0)].groupby('liborRate').term.value_counts(normalize=True)", "difficulty": 4, "dataset_id": 1}, {"desc": "where interestRate is not missing, calculate the mean of cleanUSD", "code": "df[df.interestRate.notna()].cleanUSD.mean()", "difficulty": 2, "dataset_id": 1}, {"desc": "where grace is not missing, calculate the mean of reportedValue for each value of liborRate,", "code": "df[df.grace.notna()].groupby('liborRate').reportedValue.mean()", "difficulty": 3, "dataset_id": 1}, {"desc": "where borrowerCode is equal to 7.0, count the frequency of each value of country", "code": "df[df.borrowerCode == 7.0].country.value_counts()", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows for a dataframe named merged,  where cleanUSD is greater than 30.0 and interestRate is missing,", "code": "merged[(merged.cleanUSD > 30.0) & merged.interestRate.isna()]", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows for a dataframe named merged,  where reportedValue is less than 68.0,", "code": "merged[merged.reportedValue < 68.0]", "difficulty": 1, "dataset_id": 1}, {"desc": "display all rows  where borrowerCode is not missing and year is less than 2013.0,", "code": "df[df.borrowerCode.notna() & (df.year < 2013.0)]", "difficulty": 2, "dataset_id": 1}, {"desc": "where repayment is equal to 13.0 and interestRate is not missing, count the frequency of each value of reportedUnit", "code": "df[(df.repayment == 13.0) & df.interestRate.notna()].reportedUnit.value_counts()", "difficulty": 3, "dataset_id": 1}, {"desc": "display the top 7 most common values in liborRate", "code": "df.liborRate.value_counts().head(7)", "difficulty": 1, "dataset_id": 1}, {"desc": "for a dataframe named merged,  where borrowerType is not missing, count the frequency of each value of financeType (as a percent, including missing values)", "code": "merged[merged.borrowerType.notna()].financeType.value_counts(normalize=True, dropna=False)", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows for a dataframe named df2,  where cleanUSD is equal to 164,", "code": "df2[df2.cleanUSD == 164]", "difficulty": 1, "dataset_id": 1}, {"desc": "where repayment is less than 13.0, calculate the median of reportedValue", "code": "df[df.repayment < 13.0].reportedValue.median()", "difficulty": 2, "dataset_id": 1}, {"desc": "display all rows", "code": "df", "difficulty": 0, "dataset_id": 1}, {"desc": "display all rows  where borrowerCode is greater than or equal to 3.0 and group is greater than 1.0 and repayment is less than or equal to 7.0,", "code": "df[(df.borrowerCode >= 3.0) & (df.group > 1.0) & (df.repayment <= 7.0)]", "difficulty": 3, "dataset_id": 1}, {"desc": "where borrowerCode is greater than 3.0 and group is equal to 2.0 and reportedValue is greater than or equal to 176, calculate the sum of cleanUSD for each value of liborRate,", "code": "df[(df.borrowerCode > 3.0) & (df.group == 2.0) & (df.reportedValue >= 176)].groupby('liborRate').cleanUSD.sum()", "difficulty": 5, "dataset_id": 1}, {"desc": "calculate the median of reportedValue", "code": "df.reportedValue.median()", "difficulty": 1, "dataset_id": 1}, {"desc": "where Commissioner District is less than or equal to 15.0, calculate the mean of latitude", "code": "df[df['Commissioner District'] <= 15.0].latitude.mean()", "difficulty": 2, "dataset_id": 2}, {"desc": "for a dataframe named merged,  where Commissioner District is less than 12.0, calculate the mean of Age", "code": "merged[merged['Commissioner District'] < 12.0].Age.mean()", "difficulty": 2, "dataset_id": 2}, {"desc": "display all rows for a dataframe named merged,  where latitude is not missing,", "code": "merged[merged.latitude.notna()]", "difficulty": 1, "dataset_id": 2}, {"desc": "where Primary Cause Line A is not missing, display the top 10 most common values in Secondary Cause", "code": "df[df['Primary Cause Line A'].notna()]['Secondary Cause'].value_counts().head(10)", "difficulty": 2, "dataset_id": 2}, {"desc": "where Commissioner District is missing and Residence Zip is greater than 60473.0, calculate the sum of longitude for each value of Primary Cause Line C,", "code": "df[df['Commissioner District'].isna() & (df['Residence Zip'] > 60473.0)].groupby('Primary Cause Line C').longitude.sum()", "difficulty": 4, "dataset_id": 2}, {"desc": "where Chicago Community Area is not missing and latitude is missing, count the frequency of each value of Manner of Death for each value of Secondary Cause,", "code": "df[df['Chicago Community Area'].notna() & df.latitude.isna()].groupby('Secondary Cause')['Manner of Death'].value_counts()", "difficulty": 4, "dataset_id": 2}, {"desc": "for a dataframe named merged,  where latitude is less than or equal to 41.861, calculate the sum of OBJECTID", "code": "merged[merged.latitude <= 41.861].OBJECTID.sum()", "difficulty": 2, "dataset_id": 2}, {"desc": "where Primary Cause Line A is not missing and Commissioner District is greater than 4.0, calculate the mean of Age", "code": "df[df['Primary Cause Line A'].notna() & (df['Commissioner District'] > 4.0)].Age.mean()", "difficulty": 3, "dataset_id": 2}, {"desc": "calculate the median of OBJECTID for each value of Primary Cause,", "code": "df.groupby('Primary Cause').OBJECTID.median()", "difficulty": 2, "dataset_id": 2}, {"desc": "where latitude is not missing and Chicago Ward is not missing and Residence Zip is less than or equal to 60471.0, count the frequency of each value of Chicago Community Area", "code": "df[df.latitude.notna() & df['Chicago Ward'].notna() & (df['Residence Zip'] <= 60471.0)]['Chicago Community Area'].value_counts()", "difficulty": 4, "dataset_id": 2}, {"desc": "where Secondary Cause is not missing and latitude is greater than or equal to 41.848, calculate the sum of OBJECTID", "code": "df[df['Secondary Cause'].notna() & (df.latitude >= 41.848)].OBJECTID.sum()", "difficulty": 3, "dataset_id": 2}, {"desc": "for a dataframe named merged,  where Chicago Community Area is not missing and latitude is not missing, count the frequency of each value of Incident City (including missing values)  for each value of Secondary Cause,", "code": "merged[merged['Chicago Community Area'].notna() & merged.latitude.notna()].groupby('Secondary Cause')['Incident City'].value_counts(dropna=False)", "difficulty": 4, "dataset_id": 2}, {"desc": "display all rows  where Chicago Ward is greater than or equal to 2.0 and location is not missing,", "code": "df[(df['Chicago Ward'] >= 2.0) & df.location.notna()]", "difficulty": 2, "dataset_id": 2}, {"desc": "display all rows  where Age is equal to 15.0,", "code": "df[df.Age == 15.0]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows for a dataframe named df2,  where latitude is less than 41.91,", "code": "df2[df2.latitude < 41.91]", "difficulty": 1, "dataset_id": 2}, {"desc": "calculate the median of latitude for each value of Primary Cause,", "code": "df.groupby('Primary Cause').latitude.median()", "difficulty": 2, "dataset_id": 2}, {"desc": "where Chicago Community Area is missing and Age is less than or equal to 25.0, calculate the mean of Residence Zip", "code": "df[df['Chicago Community Area'].isna() & (df.Age <= 25.0)]['Residence Zip'].mean()", "difficulty": 3, "dataset_id": 2}, {"desc": "display all rows for a dataframe named df2,  where Secondary Cause is not missing and longitude is not missing and Commissioner District is not missing,", "code": "df2[df2['Secondary Cause'].notna() & df2.longitude.notna() & df2['Commissioner District'].notna()]", "difficulty": 3, "dataset_id": 2}, {"desc": "display all rows  where Age is greater than or equal to 39.0,", "code": "df[df.Age >= 39.0]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows for a dataframe named merged,  where Secondary Cause is missing,", "code": "merged[merged['Secondary Cause'].isna()]", "difficulty": 1, "dataset_id": 2}, {"desc": "where Primary Cause Line A is missing and Secondary Cause is not missing and OBJECTID is less than or equal to 4751, display the top 3 most common values in Primary Cause", "code": "df[df['Primary Cause Line A'].isna() & df['Secondary Cause'].notna() & (df.OBJECTID <= 4751)]['Primary Cause'].value_counts().head(3)", "difficulty": 4, "dataset_id": 2}, {"desc": "display all rows", "code": "df", "difficulty": 0, "dataset_id": 2}, {"desc": "display all rows for a dataframe named df2,  where Commissioner District is less than or equal to 5.0,", "code": "df2[df2['Commissioner District'] <= 5.0]", "difficulty": 1, "dataset_id": 2}, {"desc": "where Residence Zip is greater than or equal to 60455.0 and location is not missing, calculate the mean of OBJECTID for each value of Secondary Cause,", "code": "df[(df['Residence Zip'] >= 60455.0) & df.location.notna()].groupby('Secondary Cause').OBJECTID.mean()", "difficulty": 4, "dataset_id": 2}, {"desc": "display all rows", "code": "df", "difficulty": 0, "dataset_id": 2}, {"desc": "where longitude is greater than or equal to -87.867 and Primary Cause Line A is not missing and Chicago Community Area is not missing, calculate the median of OBJECTID", "code": "df[(df.longitude >= -87.867) & df['Primary Cause Line A'].notna() & df['Chicago Community Area'].notna()].OBJECTID.median()", "difficulty": 4, "dataset_id": 2}, {"desc": "for a dataframe named df2,  where latitude is not missing, calculate the mean of longitude for each value of Secondary Cause,", "code": "df2[df2.latitude.notna()].groupby('Secondary Cause').longitude.mean()", "difficulty": 3, "dataset_id": 2}, {"desc": "where Commissioner District is equal to 11.0, calculate the sum of OBJECTID", "code": "df[df['Commissioner District'] == 11.0].OBJECTID.sum()", "difficulty": 2, "dataset_id": 2}, {"desc": "display all rows  where latitude is equal to 42.003,", "code": "df[df.latitude == 42.003]", "difficulty": 1, "dataset_id": 2}, {"desc": "for a dataframe named df2,  where location is not missing, count the frequency of each value of Incident Zip Code (as a percent)", "code": "df2[df2.location.notna()]['Incident Zip Code'].value_counts(normalize=True)", "difficulty": 2, "dataset_id": 2}, {"desc": "for a dataframe named merged,  where Chicago Ward is missing and longitude is less than -87.69, calculate the sum of Age for each value of Secondary Cause,", "code": "merged[merged['Chicago Ward'].isna() & (merged.longitude < -87.69)].groupby('Secondary Cause').Age.sum()", "difficulty": 4, "dataset_id": 2}, {"desc": "display all rows for a dataframe named merged,  where Residence Zip is less than or equal to 60089.0,", "code": "merged[merged['Residence Zip'] <= 60089.0]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows for a dataframe named df2,  where latitude is not missing,", "code": "df2[df2.latitude.notna()]", "difficulty": 1, "dataset_id": 2}, {"desc": "for a dataframe named merged,  where Chicago Community Area is missing, calculate the median of Age", "code": "merged[merged['Chicago Community Area'].isna()].Age.median()", "difficulty": 2, "dataset_id": 2}, {"desc": "where Chicago Ward is equal to 7.0, calculate the median of longitude", "code": "df[df['Chicago Ward'] == 7.0].longitude.median()", "difficulty": 2, "dataset_id": 2}, {"desc": "where Secondary Cause is not missing, calculate the mean of latitude for each value of Primary Cause Line A,", "code": "df[df['Secondary Cause'].notna()].groupby('Primary Cause Line A').latitude.mean()", "difficulty": 3, "dataset_id": 2}, {"desc": "where Primary Cause Line A is not missing and latitude is greater than or equal to 41.629, display the top 6 most common values in Primary Cause Line B", "code": "df[df['Primary Cause Line A'].notna() & (df.latitude >= 41.629)]['Primary Cause Line B'].value_counts().head(6)", "difficulty": 3, "dataset_id": 2}, {"desc": "where Commissioner District is not missing, calculate the mean of latitude", "code": "df[df['Commissioner District'].notna()].latitude.mean()", "difficulty": 2, "dataset_id": 2}, {"desc": "for a dataframe named merged,  where Chicago Community Area is not missing, count the frequency of each value of Incident City for each value of Primary Cause Line C,", "code": "merged[merged['Chicago Community Area'].notna()].groupby('Primary Cause Line C')['Incident City'].value_counts()", "difficulty": 3, "dataset_id": 2}, {"desc": "display all rows", "code": "df", "difficulty": 0, "dataset_id": 2}, {"desc": "count the frequency of each value of Manner of Death", "code": "df['Manner of Death'].value_counts()", "difficulty": 1, "dataset_id": 2}, {"desc": "for a dataframe named merged,  where longitude is equal to -87.733 and Age is less than 48.58, calculate the median of Residence Zip for each value of Primary Cause Line A,", "code": "merged[(merged.longitude == -87.733) & (merged.Age < 48.58)].groupby('Primary Cause Line A')['Residence Zip'].median()", "difficulty": 4, "dataset_id": 2}, {"desc": "display all rows  where latitude is not missing and Commissioner District is not missing and location is not missing,", "code": "df[df.latitude.notna() & df['Commissioner District'].notna() & df.location.notna()]", "difficulty": 3, "dataset_id": 2}, {"desc": "where Primary Cause Line A is missing, count the frequency of each value of Gender for each value of Secondary Cause,", "code": "df[df['Primary Cause Line A'].isna()].groupby('Secondary Cause').Gender.value_counts()", "difficulty": 3, "dataset_id": 2}, {"desc": "where Commissioner District is greater than 6.0, calculate the sum of longitude for each value of Primary Cause Line A,", "code": "df[df['Commissioner District'] > 6.0].groupby('Primary Cause Line A').longitude.sum()", "difficulty": 3, "dataset_id": 2}, {"desc": "where Commissioner District is not missing, calculate the median of latitude for each value of Secondary Cause,", "code": "df[df['Commissioner District'].notna()].groupby('Secondary Cause').latitude.median()", "difficulty": 3, "dataset_id": 2}, {"desc": "display all rows for a dataframe named merged,  where Commissioner District is less than or equal to 16.0,", "code": "merged[merged['Commissioner District'] <= 16.0]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows  where Chicago Ward is greater than 28.0,", "code": "df[df['Chicago Ward'] > 28.0]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows", "code": "df", "difficulty": 0, "dataset_id": 2}, {"desc": "where Commissioner District is missing and Chicago Ward is not missing, calculate the sum of latitude", "code": "df[df['Commissioner District'].isna() & df['Chicago Ward'].notna()].latitude.sum()", "difficulty": 3, "dataset_id": 2}, {"desc": "display all rows  where Commissioner District is not missing and latitude is not missing,", "code": "df[df['Commissioner District'].notna() & df.latitude.notna()]", "difficulty": 2, "dataset_id": 2}, {"desc": "where Chicago Ward is greater than 21.0 and latitude is less than or equal to 41.55, display the top 10 most common values in Secondary Cause, including missing values for each value of Primary Cause Line B,", "code": "df[(df['Chicago Ward'] > 21.0) & (df.latitude <= 41.55)].groupby('Primary Cause Line B')['Secondary Cause'].value_counts(dropna=False).head(10)", "difficulty": 4, "dataset_id": 2}, {"desc": "display all rows  where Primary Cause Line A is not missing and Chicago Ward is less than 28.0,", "code": "df[df['Primary Cause Line A'].notna() & (df['Chicago Ward'] < 28.0)]", "difficulty": 2, "dataset_id": 2}, {"desc": "calculate the mean of latitude for each value of Secondary Cause,", "code": "df.groupby('Secondary Cause').latitude.mean()", "difficulty": 2, "dataset_id": 2}, {"desc": "where Chicago Community Area is not missing, calculate the sum of longitude", "code": "df[df['Chicago Community Area'].notna()].longitude.sum()", "difficulty": 2, "dataset_id": 2}, {"desc": "display all rows for a dataframe named merged,  where Chicago Community Area is not missing,", "code": "merged[merged['Chicago Community Area'].notna()]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows  where Secondary Cause is not missing,", "code": "df[df['Secondary Cause'].notna()]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows for a dataframe named df2,  where Commissioner District is greater than 11.0 and OBJECTID is greater than or equal to 9294,", "code": "df2[(df2['Commissioner District'] > 11.0) & (df2.OBJECTID >= 9294)]", "difficulty": 2, "dataset_id": 2}, {"desc": "for a dataframe named df2,  where Primary Cause Line A is not missing and location is not missing and latitude is not missing, count the frequency of each value of Manner of Death", "code": "df2[df2['Primary Cause Line A'].notna() & df2.location.notna() & df2.latitude.notna()]['Manner of Death'].value_counts()", "difficulty": 4, "dataset_id": 2}, {"desc": "display all rows  where Age is equal to 46.0 and Commissioner District is missing,", "code": "df[(df.Age == 46.0) & df['Commissioner District'].isna()]", "difficulty": 2, "dataset_id": 2}, {"desc": "where Age is less than 52.0, count the frequency of each value of Incident Zip Code for each value of Secondary Cause,", "code": "df[df.Age < 52.0].groupby('Secondary Cause')['Incident Zip Code'].value_counts()", "difficulty": 3, "dataset_id": 2}, {"desc": "display all rows  where location is not missing,", "code": "df[df.location.notna()]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows  where latitude is not missing and Chicago Ward is greater than or equal to 18.0 and Primary Cause Line A is not missing,", "code": "df[df.latitude.notna() & (df['Chicago Ward'] >= 18.0) & df['Primary Cause Line A'].notna()]", "difficulty": 3, "dataset_id": 2}, {"desc": "where Residence Zip is greater than or equal to 60172.0 and Chicago Ward is less than 24.0, count the frequency of each value of Gun Related (as a percent)  for each value of Primary Cause Line C,", "code": "df[(df['Residence Zip'] >= 60172.0) & (df['Chicago Ward'] < 24.0)].groupby('Primary Cause Line C')['Gun Related'].value_counts(normalize=True)", "difficulty": 4, "dataset_id": 2}, {"desc": "display all rows for a dataframe named df2,  where latitude is less than 41.83,", "code": "df2[df2.latitude < 41.83]", "difficulty": 1, "dataset_id": 2}, {"desc": "where Commissioner District is greater than or equal to 12.0, calculate the median of latitude", "code": "df[df['Commissioner District'] >= 12.0].latitude.median()", "difficulty": 2, "dataset_id": 2}, {"desc": "where Residence Zip is less than or equal to 60403.0, calculate the median of longitude", "code": "df[df['Residence Zip'] <= 60403.0].longitude.median()", "difficulty": 2, "dataset_id": 2}, {"desc": "where Chicago Community Area is missing, calculate the median of longitude", "code": "df[df['Chicago Community Area'].isna()].longitude.median()", "difficulty": 2, "dataset_id": 2}, {"desc": "display all rows  where Residence Zip is less than 60608.0 and Commissioner District is equal to 9.0,", "code": "df[(df['Residence Zip'] < 60608.0) & (df['Commissioner District'] == 9.0)]", "difficulty": 2, "dataset_id": 2}, {"desc": "display all rows for a dataframe named merged,  where Chicago Community Area is not missing and Residence Zip is less than 60302.0,", "code": "merged[merged['Chicago Community Area'].notna() & (merged['Residence Zip'] < 60302.0)]", "difficulty": 2, "dataset_id": 2}, {"desc": "where latitude is not missing, count the frequency of each value of Primary Cause Line C (including missing values)  for each value of Primary Cause Line A,", "code": "df[df.latitude.notna()].groupby('Primary Cause Line A')['Primary Cause Line C'].value_counts(dropna=False)", "difficulty": 3, "dataset_id": 2}, {"desc": "display all rows for a dataframe named merged,  where longitude is not missing,", "code": "merged[merged.longitude.notna()]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows  where Commissioner District is greater than 4.0,", "code": "df[df['Commissioner District'] > 4.0]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows  where longitude is greater than -87.7,", "code": "df[df.longitude > -87.7]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows  where Commissioner District is equal to 5.0,", "code": "df[df['Commissioner District'] == 5.0]", "difficulty": 1, "dataset_id": 2}, {"desc": "calculate the sum of Age", "code": "df.Age.sum()", "difficulty": 1, "dataset_id": 2}, {"desc": "where Residence Zip is greater than or equal to 60445.0, display the top 10 most common values in Secondary Cause, including missing values", "code": "df[df['Residence Zip'] >= 60445.0]['Secondary Cause'].value_counts(dropna=False).head(10)", "difficulty": 2, "dataset_id": 2}, {"desc": "display all rows for a dataframe named df2,", "code": "df2", "difficulty": 0, "dataset_id": 2}, {"desc": "display all rows for a dataframe named df2,  where latitude is missing,", "code": "df2[df2.latitude.isna()]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows  where OBJECTID is less than or equal to 4979,", "code": "df[df.OBJECTID <= 4979]", "difficulty": 1, "dataset_id": 2}, {"desc": "where Commissioner District is not missing, count the frequency of each value of Manner of Death", "code": "df[df['Commissioner District'].notna()]['Manner of Death'].value_counts()", "difficulty": 2, "dataset_id": 2}, {"desc": "for a dataframe named df2,  calculate the sum of Residence Zip for each value of Primary Cause,", "code": "df2.groupby('Primary Cause')['Residence Zip'].sum()", "difficulty": 2, "dataset_id": 2}, {"desc": "where Chicago Community Area is not missing, calculate the mean of OBJECTID for each value of Primary Cause Line A,", "code": "df[df['Chicago Community Area'].notna()].groupby('Primary Cause Line A').OBJECTID.mean()", "difficulty": 3, "dataset_id": 2}, {"desc": "for a dataframe named df2,  where Chicago Community Area is not missing, calculate the sum of Age", "code": "df2[df2['Chicago Community Area'].notna()].Age.sum()", "difficulty": 2, "dataset_id": 2}, {"desc": "display all rows  where Residence Zip is less than or equal to 60164.0 and location is not missing and Chicago Ward is missing,", "code": "df[(df['Residence Zip'] <= 60164.0) & df.location.notna() & df['Chicago Ward'].isna()]", "difficulty": 3, "dataset_id": 2}, {"desc": "display all rows  where location is missing,", "code": "df[df.location.isna()]", "difficulty": 1, "dataset_id": 2}, {"desc": "calculate the median of OBJECTID", "code": "df.OBJECTID.median()", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows  where Chicago Community Area is missing,", "code": "df[df['Chicago Community Area'].isna()]", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows for a dataframe named merged,  where Chicago Community Area is not missing,", "code": "merged[merged['Chicago Community Area'].notna()]", "difficulty": 1, "dataset_id": 2}, {"desc": "for a dataframe named merged,  where location is missing, calculate the median of latitude", "code": "merged[merged.location.isna()].latitude.median()", "difficulty": 2, "dataset_id": 2}, {"desc": "display all rows for a dataframe named merged,", "code": "merged", "difficulty": 0, "dataset_id": 2}, {"desc": "calculate the sum of OBJECTID", "code": "df.OBJECTID.sum()", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows  where location is not missing and latitude is missing,", "code": "df[df.location.notna() & df.latitude.isna()]", "difficulty": 2, "dataset_id": 2}, {"desc": "where Primary Cause Line A is not missing, calculate the median of latitude", "code": "df[df['Primary Cause Line A'].notna()].latitude.median()", "difficulty": 2, "dataset_id": 2}, {"desc": "where Secondary Cause is not missing, count the frequency of each value of Primary Cause Line C for each value of Primary Cause Line A,", "code": "df[df['Secondary Cause'].notna()].groupby('Primary Cause Line A')['Primary Cause Line C'].value_counts()", "difficulty": 3, "dataset_id": 2}, {"desc": "where OBJECTID is greater than 12725.36 and longitude is not missing, count the frequency of each value of Incident Zip Code", "code": "df[(df.OBJECTID > 12725.36) & df.longitude.notna()]['Incident Zip Code'].value_counts()", "difficulty": 3, "dataset_id": 2}, {"desc": "where longitude is greater than or equal to -87.703 and Secondary Cause is not missing, display the top 5 most common values in Primary Cause Line A for each value of Primary Cause Line C,", "code": "df[(df.longitude >= -87.703) & df['Secondary Cause'].notna()].groupby('Primary Cause Line C')['Primary Cause Line A'].value_counts().head(5)", "difficulty": 4, "dataset_id": 2}, {"desc": "for a dataframe named merged,  calculate the mean of OBJECTID", "code": "merged.OBJECTID.mean()", "difficulty": 1, "dataset_id": 2}, {"desc": "display the top 9 most common values in Primary Cause", "code": "df['Primary Cause'].value_counts().head(9)", "difficulty": 1, "dataset_id": 2}, {"desc": "display all rows  where Secondary Cause is not missing,", "code": "df[df['Secondary Cause'].notna()]", "difficulty": 1, "dataset_id": 2}]}